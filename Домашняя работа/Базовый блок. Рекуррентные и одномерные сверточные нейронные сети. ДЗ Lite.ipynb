{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK4SSIkcMnDG"
   },
   "source": [
    "1. Из ноутбуков по практике \"Рекуррентные и одномерные сверточные нейронные сети\" выберите лучшую сеть, либо создайте свою.\n",
    "2. Запустите раздел \"Подготовка\"\n",
    "3. Подготовьте датасет с параметрами `VOCAB_SIZE=20'000`, `WIN_SIZE=1000`, `WIN_HOP=100`, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для  всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
    "4. Поменяйте размер словаря tokenaizera (`VOCAB_SIZE`) на `5000`, `10000`, `40000`.  Пересоздайте датасеты, при этом оставьте `WIN_SIZE=1000`, `WIN_HOP=100`.\n",
    "Обучите выбранную нейронку на этих датасетах.  Сделайте выводы об  изменении  точности распознавания авторов текстов. Результаты сведите в таблицу\n",
    "5. Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы  (`WIN_SIZE`, `WIN_HOP`) используя значения (`500`,`50`) и (`2000`,`200`). Пересоздайте датасеты, при этом оставьте `VOCAB_SIZE=20000`. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об  изменении точности распознавания авторов текстов.\n",
    "\n",
    "Результаты всей работы сведите в таблицу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lszru6V_3g3"
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4rebeM0PyTH"
   },
   "outputs": [],
   "source": [
    "# Функции операционной системы\n",
    "import os\n",
    "\n",
    "# Регулярные выражения\n",
    "import re\n",
    "\n",
    "# Работа со временем\n",
    "import time\n",
    "\n",
    "# Для работы с архивами\n",
    "import zipfile\n",
    "\n",
    "# Загрузка датасетов из облака google\n",
    "import gdown\n",
    "\n",
    "# Работа с массивами данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Функция display для отображения изображений в Jupyter Notebook\n",
    "from IPython.display import display\n",
    "\n",
    "# Функции-утилиты для работы с категориальными данными\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# Основные слои\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    MaxPooling1D,\n",
    "    SpatialDropout1D,\n",
    ")\n",
    "\n",
    "# Класс для конструирования последовательной модели нейронной сети\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Токенизатор для преобразование текстов в последовательности\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и распаковка архива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "f-7of32uP4S-",
    "outputId": "2cf8f909-1205-41b9-90c8-3e47aad7e108"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('writers.zip'):\n",
    "    # Загрузим датасет из облака\n",
    "    gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip', None, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsxkrH9rP7MS",
    "outputId": "60ee5c98-4b62-4be9-95d5-b64f3ac6d6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Стругацкие) Тестовая_2 вместе.txt\n",
      "(Рэй Брэдберри) Обучающая_22 вместе.txt\n",
      "(О. Генри) Обучающая_50 вместе.txt\n",
      "(Булгаков) Тестовая_2 вместе.txt\n",
      "(Булгаков) Обучающая_5 вместе.txt\n",
      "(Макс Фрай) Обучающая_5 вместе.txt\n",
      "(Клиффорд_Саймак) Обучающая_5 вместе.txt\n",
      "(О. Генри) Тестовая_20 вместе.txt\n",
      "(Рэй Брэдберри) Тестовая_8 вместе.txt\n",
      "(Макс Фрай) Тестовая_2 вместе.txt\n",
      "(Стругацкие) Обучающая_5 вместе.txt\n",
      "(Клиффорд_Саймак) Тестовая_2 вместе.txt\n"
     ]
    }
   ],
   "source": [
    "# Распакуем архив в папку writers\n",
    "# !unzip -o writers.zip -d writers/\n",
    "if not os.path.exists('writers'):\n",
    "    with zipfile.ZipFile('writers.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('writers')\n",
    "\n",
    "# Выводим список файлов в папке writers\n",
    "print(\"\\n\".join(os.listdir('writers')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y3fICNeqP9li"
   },
   "outputs": [],
   "source": [
    "# Настройка констант для загрузки данных\n",
    "FILE_DIR  = 'writers'                     # Папка с текстовыми файлами\n",
    "SIG_TRAIN = 'обучающая'                   # Признак обучающей выборки в имени файла\n",
    "SIG_TEST  = 'тестовая'                    # Признак тестовой выборки в имени файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulfk9v7TQBjp",
    "outputId": "7813f30c-a1a1-46ec-9b8f-1fe90b318ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавление класса \"Стругацкие\"\n",
      "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\", тестовая выборка.\n",
      "Добавление класса \"Рэй Брэдберри\"\n",
      "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\", обучающая выборка.\n",
      "Добавление класса \"О. Генри\"\n",
      "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\", обучающая выборка.\n",
      "Добавление класса \"Булгаков\"\n",
      "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\", тестовая выборка.\n",
      "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\", обучающая выборка.\n",
      "Добавление класса \"Макс Фрай\"\n",
      "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\", обучающая выборка.\n",
      "Добавление класса \"Клиффорд_Саймак\"\n",
      "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\", обучающая выборка.\n",
      "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\", тестовая выборка.\n",
      "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\", тестовая выборка.\n",
      "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\", тестовая выборка.\n",
      "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\", обучающая выборка.\n",
      "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\", тестовая выборка.\n"
     ]
    }
   ],
   "source": [
    "# Подготовим пустые списки\n",
    "\n",
    "CLASS_LIST = []  # Список классов\n",
    "text_train = []  # Список для оучающей выборки\n",
    "text_test = []  # Список для тестовой выборки\n",
    "\n",
    "# Получим списка файлов в папке\n",
    "file_list = os.listdir(FILE_DIR)\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Выделяем имя класса и типа выборки из имени файла\n",
    "    m = re.match(\"\\((.+)\\) (\\S+)_\", file_name)\n",
    "    # Если выделение получилось, то файл обрабатываем\n",
    "    if m:\n",
    "        # Получим имя класса\n",
    "        class_name = m[1]\n",
    "\n",
    "        # Получим имя выборки\n",
    "        subset_name = m[2].lower()\n",
    "\n",
    "        # Проверим тип выборки\n",
    "        is_train = SIG_TRAIN in subset_name\n",
    "        is_test = SIG_TEST in subset_name\n",
    "\n",
    "        # Если тип выборки обучающая либо тестовая - файл обрабатываем\n",
    "        if is_train or is_test:\n",
    "            # Добавляем новый класс, если его еще нет в списке\n",
    "            if class_name not in CLASS_LIST:\n",
    "                print(f'Добавление класса \"{class_name}\"')\n",
    "                CLASS_LIST.append(class_name)\n",
    "\n",
    "                # Инициализируем соответствующих классу строки текста\n",
    "                text_train.append(\"\")\n",
    "                text_test.append(\"\")\n",
    "\n",
    "            # Найдем индекс класса для добавления содержимого файла в выборку\n",
    "            cls = CLASS_LIST.index(class_name)\n",
    "            print(\n",
    "                f'Добавление файла \"{file_name}\" в класс '\n",
    "                f'\"{CLASS_LIST[cls]}\", {subset_name} выборка.'\n",
    "            )\n",
    "\n",
    "            # Откроем файл на чтение\n",
    "            with open(f\"{FILE_DIR}/{file_name}\", \"r\") as f:\n",
    "                # Загрузим содержимого файла в строку\n",
    "                text = f.read()\n",
    "            # Определим выборку, куда будет добавлено содержимое\n",
    "            subset = text_train if is_train else text_test\n",
    "\n",
    "            # Добавим текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
    "            subset[cls] += \" \" + text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QoBX2ue9zJAF"
   },
   "outputs": [],
   "source": [
    "# Определим количество классов\n",
    "CLASS_COUNT = len(CLASS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWh4j3HWzK6y",
    "outputId": "9e2db5ee-0230-49d1-c91f-208a6b1d89d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Стругацкие', 'Рэй Брэдберри', 'О. Генри', 'Булгаков', 'Макс Фрай', 'Клиффорд_Саймак']\n"
     ]
    }
   ],
   "source": [
    "# Выведем прочитанные классы текстов\n",
    "print(CLASS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GayHNBCCzMg-",
    "outputId": "2dac0d77-4e35-458a-996d-3017836b6577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем количество текстов в обучающей выборке\n",
    "print(len(text_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MOn2laWQGwq",
    "outputId": "5e7e58ab-871b-437f-e934-ccdcde89926a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс: Стругацкие\n",
      "  train:  Парень из преисподней     1     Ну и деревня! Сроду я таких деревень не видел и не знал даже, что такие деревни бывают. Дома круглые, бурые, без окон, торчат на сваях, как сторожевые вышки, а под ним\n",
      "  test :  ﻿ОТЕЛЬ «У ПОГИБШЕГО АЛЬПИНИСТА»    ГЛАВА 1     Я остановил машину, вылез и снял черные очки. Все было так, как рассказывал Згут. Отель был двухэтажный, желтый с зеленым, над крыльцом красовалась трау\n",
      "\n",
      "Класс: Рэй Брэдберри\n",
      "  train:  ﻿451° по Фаренгейту   ДОНУ КОНГДОНУ С БЛАГОДАРНОСТЬЮ   Если тебе дадут линованную бумагу, пиши поперёк.  Хуан Рамон Хименес   Часть 1  ОЧАГ И САЛАМАНДРА   Жечь было наслаждением. Какое-то особое насл\n",
      "  test :  ﻿Марсианские хроники   МОЕЙ ЖЕНЕ МАРГАРЕТ С ИСКРЕННЕЙ ЛЮБОВЬЮ   «Великое дело – способность удивляться, – сказал философ. – Космические полеты снова сделали всех нас детьми».   Январь 1999  Ракетное \n",
      "\n",
      "Класс: О. Генри\n",
      "  train:  «Лиса-на-рассвете»   Коралио нежился в полуденном зное, как томная красавица в сурово хранимом гареме. Город лежал у самого моря на полоске наносной земли. Он казался брильянтиком, вкрапленным в ярко\n",
      "  test :  ﻿Багдадская птица   Без всякого сомнения, дух и гений калифа Гаруна аль-Рашида осенил маркграфа Августа-Михаила фон Паульсена Квигга.  Ресторан Квигга находится на Четвертой авеню — на улице, которую\n",
      "\n",
      "Класс: Булгаков\n",
      "  train:  ﻿Белая гвардия   Посвящается[1]  Любови Евгеньевне Белозерской[2]  Пошел мелкий снег и вдруг повалил хло-  пьями. Ветер завыл; сделалась метель.  В одно мгновение темное небо смешалось с  снежным мор\n",
      "  test :  ﻿Дон Кихот ДЕЙСТВУЮЩИЕ ЛИЦА Алонсо Кихано, он же Дон Кихот Ламанчский.  Антония – его племянница.  Ключница Дон Кихота.  Санчо Панса – оруженосец Дон Кихота.  Перо Перес – деревенский священник, лице\n",
      "\n",
      "Класс: Макс Фрай\n",
      "  train:  ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежедневно снится какая-то дичь! – сердито сказал я Джуффину. – Сглазили они меня, что ли? А собственно, по\n",
      "  test :  ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, ответ на закономерный вопрос: «Как меня сюда занесло?» – вряд ли принесёт практическую пользу. Зато пои\n",
      "\n",
      "Класс: Клиффорд_Саймак\n",
      "  train:  ﻿Всё живое...     Когда я выехал из нашего городишка и повернул на шоссе, позади оказался грузовик. Этакая тяжелая громадина с прицепом, и неслась она во весь дух. Шоссе здесь срезает угол городка, и\n",
      "  test :  ﻿Зачарованное паломничество    1  Гоблин со стропил следил за прячущимся монахом, который шпионил за ученым. Гоблин ненавидел монаха и имел для этого все основания. Монах никого не ненавидел и не люб\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверим загрузки: выведем начальные отрывки из каждого класса\n",
    "\n",
    "for cls in range(CLASS_COUNT):                   # Запустим цикл по числу классов\n",
    "    print(f'Класс: {CLASS_LIST[cls]}')           # Выведем имя класса\n",
    "    print(f'  train: {text_train[cls][:200]}')   # Выведем фрагмент обучающей выборки\n",
    "    print(f'  test : {text_test[cls][:200]}')    # Выведем фрагмент тестовой выборки\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контекстный менеджер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y2FgTG41QKaT"
   },
   "outputs": [],
   "source": [
    "# Контекстный менеджер для измерения времени операций\n",
    "# Операция обертывается менеджером с помощью оператора with\n",
    "\n",
    "class timex:\n",
    "    def __enter__(self):\n",
    "        # Фиксация времени старта процесса\n",
    "        self.t = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        # Вывод времени работы\n",
    "        print('Время обработки: {:.2f} с'.format(time.time() - self.t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSqt4mshIKzf"
   },
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Списки параметров токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZES=(5000, 10000, 20000, 40000)\n",
    "WIN_PARAMS=((500, 50), (1000, 100), (2000, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для деления последовательностей на окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция разбиения последовательности на отрезки скользящим окном\n",
    "# На входе - последовательность индексов, размер окна, шаг окна\n",
    "def split_sequence(sequence, win_size, hop):\n",
    "    # Последовательность разбивается на части до последнего полного окна\n",
    "    return [\n",
    "        sequence[i : i + win_size] for i in range(0, len(sequence) - win_size + 1, hop)\n",
    "    ]\n",
    "\n",
    "\n",
    "# Функция формирования выборок из последовательностей индексов\n",
    "# формирует выборку отрезков и соответствующих им меток классов в виде one hot encoding\n",
    "def vectorize_sequence(seq_list, win_size, hop):\n",
    "    # В списке последовательности следуют в порядке их классов\n",
    "    # Всего последовательностей в списке ровно столько, сколько классов\n",
    "    class_count = len(seq_list)\n",
    "\n",
    "    # Списки для исходных векторов и категориальных меток класса\n",
    "    x, y = [], []\n",
    "\n",
    "    # Для каждого класса:\n",
    "    for cls in range(class_count):\n",
    "        # Разбиение последовательности класса cls на отрезки\n",
    "        vectors = split_sequence(seq_list[cls], win_size, hop)\n",
    "        # Добавление отрезков в выборку\n",
    "        x += vectors\n",
    "        # Для всех отрезков класса cls добавление меток класса в виде OHE\n",
    "        y += [utils.to_categorical(cls, class_count)] * len(vectors)\n",
    "\n",
    "    # Возврат результатов как numpy-массивов\n",
    "    return np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция создания выборок и модели, обучение модели на созданных выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция подготовки данных, создания и обучения нейронной сети\n",
    "def preparation_and_creation_ns(\n",
    "    models_list, seq_train, seq_test, vocab_size, win_size, win_hope\n",
    "):\n",
    "    with timex():  # Подготовка выборок\n",
    "        x_train, y_train = vectorize_sequence(seq_train, win_size, win_hope)\n",
    "        x_test, y_test = vectorize_sequence(seq_test, win_size, win_hope)\n",
    "\n",
    "    model = Sequential(  # Создание модели нейронной сети\n",
    "        [\n",
    "            Embedding(vocab_size, 10),\n",
    "            SpatialDropout1D(0.2),\n",
    "            BatchNormalization(),\n",
    "            Conv1D(20, 5, activation=\"relu\", padding=\"same\"),\n",
    "            Conv1D(20, 5, activation=\"relu\"),\n",
    "            MaxPooling1D(2),\n",
    "            Dropout(0.2),\n",
    "            BatchNormalization(),\n",
    "            Flatten(),\n",
    "            Dense(CLASS_COUNT, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(  # Компиляция модели\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(  # Обучение модели\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=256,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    models_list.append(  # Добавление параметров модели в список\n",
    "        {\n",
    "            \"VOCAB_SIZE\": vocab_size,\n",
    "            \"WIN_SIZE\": win_size,\n",
    "            \"WIN_HOPE\": win_hope,\n",
    "            \"Точность\": history.history[\"accuracy\"][-1],\n",
    "            \"Точность на проверочной выборке\": history.history[\"val_accuracy\"][-1],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл итерации по VOCAB_SIZES, \n",
    "### и вложенный цикл итерации по WIN_PARAMS при vocab_size=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LP8G65N-_36M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обработки: 3.33 с\n",
      "Время обработки: 0.80 с\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 76ms/step - accuracy: 0.3215 - loss: 1.9572 - val_accuracy: 0.1253 - val_loss: 2.3560\n",
      "Epoch 2/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8158 - loss: 0.4899 - val_accuracy: 0.0782 - val_loss: 5.3864\n",
      "Epoch 3/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9779 - loss: 0.0773 - val_accuracy: 0.0981 - val_loss: 6.7929\n",
      "Epoch 4/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0279 - val_accuracy: 0.1971 - val_loss: 7.4754\n",
      "Epoch 5/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0226 - val_accuracy: 0.1971 - val_loss: 7.4412\n",
      "Epoch 6/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 0.0129 - val_accuracy: 0.2022 - val_loss: 5.3152\n",
      "Epoch 7/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.3494 - val_loss: 3.4185\n",
      "Epoch 8/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0158 - val_accuracy: 0.5013 - val_loss: 2.6205\n",
      "Epoch 9/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.6114 - val_loss: 1.7346\n",
      "Epoch 10/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.5763 - val_loss: 1.9536\n",
      "Epoch 11/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 0.0099 - val_accuracy: 0.6430 - val_loss: 1.3012\n",
      "Epoch 12/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.5992 - val_loss: 1.4297\n",
      "Epoch 13/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.5987 - val_loss: 1.6992\n",
      "Epoch 14/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.7042 - val_loss: 1.1577\n",
      "Epoch 15/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.7043 - val_loss: 1.1284\n",
      "Epoch 16/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.6134 - val_loss: 1.6701\n",
      "Epoch 17/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.7091 - val_loss: 1.2881\n",
      "Epoch 18/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.6896 - val_loss: 1.2762\n",
      "Epoch 19/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.6219 - val_loss: 2.2513\n",
      "Epoch 20/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.6158 - val_loss: 1.7280\n",
      "Epoch 21/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.6606 - val_loss: 1.4848\n",
      "Epoch 22/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0084 - val_accuracy: 0.6351 - val_loss: 1.9398\n",
      "Epoch 23/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 0.0088 - val_accuracy: 0.6216 - val_loss: 1.8858\n",
      "Epoch 24/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.7323 - val_loss: 1.0668\n",
      "Epoch 25/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.7063 - val_loss: 1.1676\n",
      "Epoch 26/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.7308 - val_loss: 1.1658\n",
      "Epoch 27/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.6430 - val_loss: 1.5202\n",
      "Epoch 28/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.6876 - val_loss: 1.4384\n",
      "Epoch 29/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.7489 - val_loss: 1.0754\n",
      "Epoch 30/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.7380 - val_loss: 1.3065\n",
      "Epoch 31/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.7263 - val_loss: 1.1363\n",
      "Epoch 32/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.6051 - val_loss: 1.8696\n",
      "Epoch 33/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0061 - val_accuracy: 0.4927 - val_loss: 2.8779\n",
      "Epoch 34/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.6195 - val_loss: 2.2331\n",
      "Epoch 35/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.6641 - val_loss: 1.7189\n",
      "Epoch 36/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.6502 - val_loss: 1.8844\n",
      "Epoch 37/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.6470 - val_loss: 1.7349\n",
      "Epoch 38/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.6319 - val_loss: 1.7406\n",
      "Epoch 39/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.6707 - val_loss: 1.4460\n",
      "Epoch 40/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.7405 - val_loss: 1.2978\n",
      "Epoch 41/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.6161 - val_loss: 2.1799\n",
      "Epoch 42/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.5715 - val_loss: 2.3661\n",
      "Epoch 43/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.6291 - val_loss: 1.7077\n",
      "Epoch 44/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.6928 - val_loss: 1.5189\n",
      "Epoch 45/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.6449 - val_loss: 2.1165\n",
      "Epoch 46/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.7125 - val_loss: 1.2533\n",
      "Epoch 47/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.6137 - val_loss: 2.0245\n",
      "Epoch 48/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.6642 - val_loss: 1.9822\n",
      "Epoch 49/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.5912 - val_loss: 2.1739\n",
      "Epoch 50/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.6325 - val_loss: 2.5482\n",
      "Epoch 51/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0024 - val_accuracy: 0.5963 - val_loss: 3.6703\n",
      "Epoch 52/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.5666 - val_loss: 3.6932\n",
      "Epoch 53/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.6217 - val_loss: 2.5219\n",
      "Epoch 54/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0033 - val_accuracy: 0.6330 - val_loss: 2.5010\n",
      "Epoch 55/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.6532 - val_loss: 2.0049\n",
      "Epoch 56/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.4934 - val_loss: 3.1394\n",
      "Epoch 57/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.5748 - val_loss: 2.9001\n",
      "Epoch 58/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 8.0836e-04 - val_accuracy: 0.6158 - val_loss: 2.8762\n",
      "Epoch 59/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0016 - val_accuracy: 0.6506 - val_loss: 2.9287\n",
      "Epoch 60/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.5775 - val_loss: 4.0073\n",
      "Epoch 61/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.7027 - val_loss: 2.5182\n",
      "Epoch 62/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.6726 - val_loss: 2.3967\n",
      "Epoch 63/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.6310 - val_loss: 2.8230\n",
      "Epoch 64/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0032 - val_accuracy: 0.4480 - val_loss: 6.0310\n",
      "Epoch 65/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.6032 - val_loss: 3.8741\n",
      "Epoch 66/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.5709 - val_loss: 3.4906\n",
      "Epoch 67/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.6044 - val_loss: 3.3296\n",
      "Epoch 68/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.6185 - val_loss: 2.8451\n",
      "Epoch 69/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.5882 - val_loss: 2.7877\n",
      "Epoch 70/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.6234 - val_loss: 3.2573\n",
      "Epoch 71/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.5465 - val_loss: 4.2375\n",
      "Epoch 72/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.5652 - val_loss: 4.1616\n",
      "Epoch 73/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.5743 - val_loss: 3.5109\n",
      "Epoch 74/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 7.1635e-04 - val_accuracy: 0.6357 - val_loss: 3.0464\n",
      "Epoch 75/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.5661 - val_loss: 4.0931\n",
      "Epoch 76/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.6010 - val_loss: 3.5109\n",
      "Epoch 77/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0023 - val_accuracy: 0.5645 - val_loss: 3.6324\n",
      "Epoch 78/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 9.5231e-04 - val_accuracy: 0.6258 - val_loss: 3.7219\n",
      "Epoch 79/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 0.6108 - val_loss: 3.4682\n",
      "Epoch 80/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0014 - val_accuracy: 0.6433 - val_loss: 3.6411\n",
      "Epoch 81/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.6515 - val_loss: 2.7814\n",
      "Epoch 82/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.5239 - val_loss: 4.0774\n",
      "Epoch 83/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.6026 - val_loss: 3.3687\n",
      "Epoch 84/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.5763 - val_loss: 4.3470\n",
      "Epoch 85/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.6004 - val_loss: 3.5933\n",
      "Epoch 86/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.5670 - val_loss: 3.5721\n",
      "Epoch 87/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.6328 - val_loss: 3.2020\n",
      "Epoch 88/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.4809 - val_loss: 5.6457\n",
      "Epoch 89/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.5643 - val_loss: 4.3312\n",
      "Epoch 90/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.5595 - val_loss: 3.8830\n",
      "Epoch 91/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.6132 - val_loss: 3.4069\n",
      "Epoch 92/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.4701 - val_loss: 5.6472\n",
      "Epoch 93/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.6090 - val_loss: 4.0807\n",
      "Epoch 94/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.6342 - val_loss: 3.9336\n",
      "Epoch 95/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.5854 - val_loss: 3.3876\n",
      "Epoch 96/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.6226 - val_loss: 3.7947\n",
      "Epoch 97/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.6271 - val_loss: 3.6420\n",
      "Epoch 98/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.6146 - val_loss: 4.4328\n",
      "Epoch 99/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.5980 - val_loss: 4.4028\n",
      "Epoch 100/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 3.5607e-04 - val_accuracy: 0.6054 - val_loss: 3.7132\n",
      "Время обработки: 3.34 с\n",
      "Время обработки: 3.84 с\n",
      "Epoch 1/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.3080 - loss: 2.0381 - val_accuracy: 0.0782 - val_loss: 2.5065\n",
      "Epoch 2/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8321 - loss: 0.4569 - val_accuracy: 0.0782 - val_loss: 4.3163\n",
      "Epoch 3/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0573 - val_accuracy: 0.1280 - val_loss: 6.2725\n",
      "Epoch 4/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0265 - val_accuracy: 0.0862 - val_loss: 7.0184\n",
      "Epoch 5/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 0.0152 - val_accuracy: 0.2106 - val_loss: 6.7992\n",
      "Epoch 6/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.0117 - val_accuracy: 0.2130 - val_loss: 5.4777\n",
      "Epoch 7/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9977 - loss: 0.0089 - val_accuracy: 0.2839 - val_loss: 4.0033\n",
      "Epoch 8/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.3815 - val_loss: 3.4112\n",
      "Epoch 9/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0069 - val_accuracy: 0.4156 - val_loss: 3.0909\n",
      "Epoch 10/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.5776 - val_loss: 1.8928\n",
      "Epoch 11/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.4996 - val_loss: 2.2522\n",
      "Epoch 12/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.0074 - val_accuracy: 0.5012 - val_loss: 2.3694\n",
      "Epoch 13/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.5969 - val_loss: 1.8223\n",
      "Epoch 14/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.5034 - val_loss: 2.4750\n",
      "Epoch 15/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.5564 - val_loss: 2.0378\n",
      "Epoch 16/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.6028 - val_loss: 1.8862\n",
      "Epoch 17/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.6485 - val_loss: 1.6929\n",
      "Epoch 18/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.5954 - val_loss: 2.3205\n",
      "Epoch 19/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.6056 - val_loss: 1.8798\n",
      "Epoch 20/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.6207 - val_loss: 1.8151\n",
      "Epoch 21/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.5142 - val_loss: 2.4834\n",
      "Epoch 22/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9973 - loss: 0.0069 - val_accuracy: 0.3736 - val_loss: 4.1190\n",
      "Epoch 23/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.5863 - val_loss: 2.3121\n",
      "Epoch 24/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9986 - loss: 0.0032 - val_accuracy: 0.6014 - val_loss: 2.2664\n",
      "Epoch 25/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.6086 - val_loss: 2.3061\n",
      "Epoch 26/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.6225 - val_loss: 2.1972\n",
      "Epoch 27/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.6231 - val_loss: 2.1506\n",
      "Epoch 28/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.5832 - val_loss: 2.4735\n",
      "Epoch 29/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.5503 - val_loss: 2.7349\n",
      "Epoch 30/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0047 - val_accuracy: 0.5663 - val_loss: 2.7129\n",
      "Epoch 31/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.6337 - val_loss: 2.1484\n",
      "Epoch 32/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.5672 - val_loss: 3.2930\n",
      "Epoch 33/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.5879 - val_loss: 2.6351\n",
      "Epoch 34/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.5947 - val_loss: 2.5757\n",
      "Epoch 35/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.6641 - val_loss: 2.0461\n",
      "Epoch 36/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.5959 - val_loss: 2.3357\n",
      "Epoch 37/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.4333 - val_loss: 3.7737\n",
      "Epoch 38/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.4520 - val_loss: 4.0776\n",
      "Epoch 39/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.4945 - val_loss: 4.1788\n",
      "Epoch 40/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0040 - val_accuracy: 0.6011 - val_loss: 2.4285\n",
      "Epoch 41/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.5921 - val_loss: 2.4380\n",
      "Epoch 42/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.5462 - val_loss: 3.8208\n",
      "Epoch 43/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.5556 - val_loss: 2.6540\n",
      "Epoch 44/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.5873 - val_loss: 2.5008\n",
      "Epoch 45/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.5031 - val_loss: 3.8229\n",
      "Epoch 46/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.4957 - val_loss: 3.2435\n",
      "Epoch 47/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.5977 - val_loss: 2.4881\n",
      "Epoch 48/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0067 - val_accuracy: 0.5692 - val_loss: 2.8977\n",
      "Epoch 49/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.6084 - val_loss: 2.4930\n",
      "Epoch 50/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.5911 - val_loss: 2.7179\n",
      "Epoch 51/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.4601 - val_loss: 4.0375\n",
      "Epoch 52/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0078 - val_accuracy: 0.5488 - val_loss: 3.4631\n",
      "Epoch 53/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.4840 - val_loss: 3.6425\n",
      "Epoch 54/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.6008 - val_loss: 2.6087\n",
      "Epoch 55/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.4912 - val_loss: 3.9091\n",
      "Epoch 56/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.5933 - val_loss: 2.7522\n",
      "Epoch 57/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 8.8908e-04 - val_accuracy: 0.5794 - val_loss: 3.0429\n",
      "Epoch 58/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.4696 - val_loss: 3.7244\n",
      "Epoch 59/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.6363 - val_loss: 2.4388\n",
      "Epoch 60/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.5863 - val_loss: 2.9772\n",
      "Epoch 61/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.6028 - val_loss: 3.6661\n",
      "Epoch 62/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.4844 - val_loss: 4.2762\n",
      "Epoch 63/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.5537 - val_loss: 3.4543\n",
      "Epoch 64/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.6352 - val_loss: 2.4725\n",
      "Epoch 65/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.5341 - val_loss: 3.7527\n",
      "Epoch 66/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0056 - val_accuracy: 0.5728 - val_loss: 2.7837\n",
      "Epoch 67/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9977 - loss: 0.0108 - val_accuracy: 0.5761 - val_loss: 2.9252\n",
      "Epoch 68/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.6182 - val_loss: 2.8249\n",
      "Epoch 69/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.6388 - val_loss: 2.7977\n",
      "Epoch 70/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.5607 - val_loss: 3.0745\n",
      "Epoch 71/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0037 - val_accuracy: 0.5109 - val_loss: 3.8723\n",
      "Epoch 72/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.4771 - val_loss: 4.5250\n",
      "Epoch 73/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.6063 - val_loss: 2.8368\n",
      "Epoch 74/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.6656 - val_loss: 2.3406\n",
      "Epoch 75/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0019 - val_accuracy: 0.4885 - val_loss: 4.5935\n",
      "Epoch 76/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.5256 - val_loss: 3.4746\n",
      "Epoch 77/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9991 - loss: 0.0047 - val_accuracy: 0.5800 - val_loss: 2.7488\n",
      "Epoch 78/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.6028 - val_loss: 2.9985\n",
      "Epoch 79/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.5504 - val_loss: 4.2866\n",
      "Epoch 80/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.5740 - val_loss: 3.2201\n",
      "Epoch 81/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.5589 - val_loss: 4.5160\n",
      "Epoch 82/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.5452 - val_loss: 3.7505\n",
      "Epoch 83/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.3794 - val_loss: 6.7574\n",
      "Epoch 84/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.5305 - val_loss: 4.0619\n",
      "Epoch 85/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.4720 - val_loss: 5.4348\n",
      "Epoch 86/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.5574 - val_loss: 3.6494\n",
      "Epoch 87/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7177e-04 - val_accuracy: 0.6222 - val_loss: 2.9230\n",
      "Epoch 88/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.5661 - val_loss: 3.2692\n",
      "Epoch 89/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.6041 - val_loss: 3.0506\n",
      "Epoch 90/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.5485 - val_loss: 3.4961\n",
      "Epoch 91/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.6488 - val_loss: 2.3873\n",
      "Epoch 92/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.6258 - val_loss: 2.6468\n",
      "Epoch 93/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.5001 - val_loss: 3.8764\n",
      "Epoch 94/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.5226 - val_loss: 3.9350\n",
      "Epoch 95/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.4970 - val_loss: 4.4883\n",
      "Epoch 96/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.6034 - val_loss: 3.6842\n",
      "Epoch 97/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.5230 - val_loss: 4.0723\n",
      "Epoch 98/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.4785 - val_loss: 4.9334\n",
      "Epoch 99/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.5625 - val_loss: 4.2001\n",
      "Epoch 100/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.5776 - val_loss: 4.0086\n",
      "Время обработки: 3.36 с\n",
      "Время обработки: 0.88 с\n",
      "Epoch 1/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.3584 - loss: 1.8206 - val_accuracy: 0.2944 - val_loss: 1.7612\n",
      "Epoch 2/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.0851 - val_accuracy: 0.4291 - val_loss: 1.3604\n",
      "Epoch 3/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0244 - val_accuracy: 0.5980 - val_loss: 1.2543\n",
      "Epoch 4/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0395 - val_accuracy: 0.6434 - val_loss: 1.0478\n",
      "Epoch 5/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0143 - val_accuracy: 0.6826 - val_loss: 1.1103\n",
      "Epoch 6/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0105 - val_accuracy: 0.6961 - val_loss: 1.1709\n",
      "Epoch 7/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0053 - val_accuracy: 0.4426 - val_loss: 3.8357\n",
      "Epoch 8/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9754 - loss: 0.1001 - val_accuracy: 0.6873 - val_loss: 1.2962\n",
      "Epoch 9/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0085 - val_accuracy: 0.6514 - val_loss: 1.7024\n",
      "Epoch 10/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0412 - val_accuracy: 0.7292 - val_loss: 1.0467\n",
      "Epoch 11/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.6526 - val_loss: 1.3902\n",
      "Epoch 12/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.7094 - val_loss: 1.1360\n",
      "Epoch 13/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0099 - val_accuracy: 0.6584 - val_loss: 1.3578\n",
      "Epoch 14/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.6821 - val_loss: 1.3202\n",
      "Epoch 15/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.6638 - val_loss: 1.4533\n",
      "Epoch 16/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0364 - val_accuracy: 0.5921 - val_loss: 1.8905\n",
      "Epoch 17/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.6621 - val_loss: 1.5032\n",
      "Epoch 18/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.6987 - val_loss: 1.5532\n",
      "Epoch 19/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.0499 - val_accuracy: 0.6451 - val_loss: 1.7985\n",
      "Epoch 20/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.6473 - val_loss: 1.8110\n",
      "Epoch 21/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0045 - val_accuracy: 0.6868 - val_loss: 1.4691\n",
      "Epoch 22/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.6768 - val_loss: 1.5776\n",
      "Epoch 23/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.6729 - val_loss: 1.8660\n",
      "Epoch 24/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0549 - val_accuracy: 0.6093 - val_loss: 2.2610\n",
      "Epoch 25/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.6515 - val_loss: 1.8801\n",
      "Epoch 26/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.6546 - val_loss: 1.9839\n",
      "Epoch 27/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.6572 - val_loss: 2.0089\n",
      "Epoch 28/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0335 - val_accuracy: 0.6179 - val_loss: 2.2806\n",
      "Epoch 29/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0430 - val_accuracy: 0.5290 - val_loss: 3.0819\n",
      "Epoch 30/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0240 - val_accuracy: 0.6087 - val_loss: 2.1803\n",
      "Epoch 31/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.6296 - val_loss: 2.1018\n",
      "Epoch 32/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9939 - loss: 0.0259 - val_accuracy: 0.6079 - val_loss: 2.0597\n",
      "Epoch 33/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0029 - val_accuracy: 0.6441 - val_loss: 1.8812\n",
      "Epoch 34/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.6045 - val_loss: 2.3173\n",
      "Epoch 35/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0121 - val_accuracy: 0.5684 - val_loss: 2.5274\n",
      "Epoch 36/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.6148 - val_loss: 2.2002\n",
      "Epoch 37/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.6208 - val_loss: 2.2097\n",
      "Epoch 38/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0204 - val_accuracy: 0.6162 - val_loss: 2.2188\n",
      "Epoch 39/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.6441 - val_loss: 1.9630\n",
      "Epoch 40/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0361 - val_accuracy: 0.5587 - val_loss: 2.9061\n",
      "Epoch 41/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.6164 - val_loss: 2.1656\n",
      "Epoch 42/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.6281 - val_loss: 2.0064\n",
      "Epoch 43/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.6310 - val_loss: 2.0572\n",
      "Epoch 44/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.6285 - val_loss: 2.0877\n",
      "Epoch 45/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.6223 - val_loss: 2.1595\n",
      "Epoch 46/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.6132 - val_loss: 2.2252\n",
      "Epoch 47/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.6208 - val_loss: 2.1787\n",
      "Epoch 48/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.6405 - val_loss: 2.0036\n",
      "Epoch 49/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.6180 - val_loss: 2.2686\n",
      "Epoch 50/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0084 - val_accuracy: 0.6182 - val_loss: 2.3517\n",
      "Epoch 51/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.5811 - val_loss: 2.6282\n",
      "Epoch 52/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.6063 - val_loss: 2.6706\n",
      "Epoch 53/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.6220 - val_loss: 2.5593\n",
      "Epoch 54/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0221 - val_accuracy: 0.6074 - val_loss: 2.6710\n",
      "Epoch 55/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.6275 - val_loss: 2.4117\n",
      "Epoch 56/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.6238 - val_loss: 2.4252\n",
      "Epoch 57/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.6258 - val_loss: 2.3829\n",
      "Epoch 58/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.6404 - val_loss: 2.3436\n",
      "Epoch 59/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.6313 - val_loss: 2.4542\n",
      "Epoch 60/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.6223 - val_loss: 2.6146\n",
      "Epoch 61/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0165 - val_accuracy: 0.5885 - val_loss: 3.0103\n",
      "Epoch 62/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.5778 - val_loss: 3.0923\n",
      "Epoch 63/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.6149 - val_loss: 2.6912\n",
      "Epoch 64/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.6252 - val_loss: 2.5524\n",
      "Epoch 65/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.6153 - val_loss: 2.6749\n",
      "Epoch 66/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.5761 - val_loss: 3.3891\n",
      "Epoch 67/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0711 - val_accuracy: 0.6220 - val_loss: 2.3283\n",
      "Epoch 68/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.6271 - val_loss: 2.3424\n",
      "Epoch 69/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.6184 - val_loss: 2.3415\n",
      "Epoch 70/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0259 - val_accuracy: 0.5647 - val_loss: 2.7189\n",
      "Epoch 71/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.5697 - val_loss: 2.7708\n",
      "Epoch 72/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0155 - val_accuracy: 0.5898 - val_loss: 2.7747\n",
      "Epoch 73/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.5980 - val_loss: 2.5404\n",
      "Epoch 74/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.5686 - val_loss: 2.8005\n",
      "Epoch 75/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 9.1266e-04 - val_accuracy: 0.5907 - val_loss: 2.6679\n",
      "Epoch 76/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.5933 - val_loss: 2.6129\n",
      "Epoch 77/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0243 - val_accuracy: 0.5552 - val_loss: 3.2840\n",
      "Epoch 78/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.5823 - val_loss: 2.7129\n",
      "Epoch 79/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.5945 - val_loss: 2.6218\n",
      "Epoch 80/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0134 - val_accuracy: 0.5894 - val_loss: 2.7150\n",
      "Epoch 81/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.5829 - val_loss: 2.7772\n",
      "Epoch 82/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.5861 - val_loss: 2.7657\n",
      "Epoch 83/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0209 - val_accuracy: 0.5616 - val_loss: 2.9515\n",
      "Epoch 84/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.5578 - val_loss: 2.9839\n",
      "Epoch 85/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0209 - val_accuracy: 0.5362 - val_loss: 3.2561\n",
      "Epoch 86/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.5598 - val_loss: 2.9980\n",
      "Epoch 87/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.5635 - val_loss: 3.1080\n",
      "Epoch 88/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.5575 - val_loss: 3.1635\n",
      "Epoch 89/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.5638 - val_loss: 3.1351\n",
      "Epoch 90/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 9.7182e-04 - val_accuracy: 0.5564 - val_loss: 3.2934\n",
      "Epoch 91/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 8.5286e-04 - val_accuracy: 0.5639 - val_loss: 3.2197\n",
      "Epoch 92/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 9.4890e-04 - val_accuracy: 0.5730 - val_loss: 3.1041\n",
      "Epoch 93/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.6044 - val_loss: 2.9508\n",
      "Epoch 94/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.5728 - val_loss: 3.2474\n",
      "Epoch 95/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.5674 - val_loss: 3.3335\n",
      "Epoch 96/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.5697 - val_loss: 3.3340\n",
      "Epoch 97/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.5499 - val_loss: 3.7754\n",
      "Epoch 98/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0161 - val_accuracy: 0.6036 - val_loss: 3.0357\n",
      "Epoch 99/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 8.3550e-04 - val_accuracy: 0.5835 - val_loss: 3.2171\n",
      "Epoch 100/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 9.9295e-04 - val_accuracy: 0.5627 - val_loss: 3.4910\n",
      "Время обработки: 0.84 с\n",
      "Epoch 1/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.3488 - loss: 1.9177 - val_accuracy: 0.1968 - val_loss: 1.8140\n",
      "Epoch 2/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9078 - loss: 0.2609 - val_accuracy: 0.1971 - val_loss: 2.0311\n",
      "Epoch 3/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.0361 - val_accuracy: 0.1964 - val_loss: 3.8013\n",
      "Epoch 4/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.0169 - val_accuracy: 0.0806 - val_loss: 5.2423\n",
      "Epoch 5/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0123 - val_accuracy: 0.0782 - val_loss: 7.1795\n",
      "Epoch 6/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0085 - val_accuracy: 0.0844 - val_loss: 6.4279\n",
      "Epoch 7/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.2073 - val_loss: 5.0526\n",
      "Epoch 8/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.2676 - val_loss: 4.5976\n",
      "Epoch 9/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.4342 - val_loss: 2.6443\n",
      "Epoch 10/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.5175 - val_loss: 2.0471\n",
      "Epoch 11/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.5323 - val_loss: 2.2605\n",
      "Epoch 12/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.6210 - val_loss: 1.5616\n",
      "Epoch 13/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.6240 - val_loss: 1.6127\n",
      "Epoch 14/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.5503 - val_loss: 2.3770\n",
      "Epoch 15/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.5935 - val_loss: 1.8913\n",
      "Epoch 16/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.6494 - val_loss: 1.5095\n",
      "Epoch 17/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.5927 - val_loss: 1.7603\n",
      "Epoch 18/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.5319 - val_loss: 2.2911\n",
      "Epoch 19/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.5809 - val_loss: 2.7008\n",
      "Epoch 20/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.6541 - val_loss: 1.7100\n",
      "Epoch 21/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.5480 - val_loss: 2.4568\n",
      "Epoch 22/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.5841 - val_loss: 1.7615\n",
      "Epoch 23/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.6249 - val_loss: 1.5515\n",
      "Epoch 24/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.5709 - val_loss: 2.0970\n",
      "Epoch 25/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.5226 - val_loss: 2.6857\n",
      "Epoch 26/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.5232 - val_loss: 3.2437\n",
      "Epoch 27/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.6250 - val_loss: 1.8152\n",
      "Epoch 28/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.6189 - val_loss: 2.1362\n",
      "Epoch 29/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.5823 - val_loss: 2.1962\n",
      "Epoch 30/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.6322 - val_loss: 1.7257\n",
      "Epoch 31/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.4829 - val_loss: 2.7561\n",
      "Epoch 32/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0019 - val_accuracy: 0.6319 - val_loss: 1.6375\n",
      "Epoch 33/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.4580 - val_loss: 3.7472\n",
      "Epoch 34/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.5426 - val_loss: 2.5468\n",
      "Epoch 35/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.6162 - val_loss: 1.9938\n",
      "Epoch 36/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.6558 - val_loss: 1.7803\n",
      "Epoch 37/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.6744 - val_loss: 1.6819\n",
      "Epoch 38/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.5866 - val_loss: 3.4757\n",
      "Epoch 39/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.5269 - val_loss: 3.2220\n",
      "Epoch 40/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.6686 - val_loss: 1.8614\n",
      "Epoch 41/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.6017 - val_loss: 2.1462\n",
      "Epoch 42/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.5509 - val_loss: 2.8389\n",
      "Epoch 43/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.6541 - val_loss: 2.0123\n",
      "Epoch 44/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.5440 - val_loss: 4.4317\n",
      "Epoch 45/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.5930 - val_loss: 2.2503\n",
      "Epoch 46/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.7130 - val_loss: 1.5511\n",
      "Epoch 47/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.6587 - val_loss: 2.1434\n",
      "Epoch 48/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.6261 - val_loss: 2.3742\n",
      "Epoch 49/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.6197 - val_loss: 2.5187\n",
      "Epoch 50/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.6541 - val_loss: 1.9826\n",
      "Epoch 51/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.5724 - val_loss: 2.8359\n",
      "Epoch 52/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.6656 - val_loss: 1.8218\n",
      "Epoch 53/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.5512 - val_loss: 3.0170\n",
      "Epoch 54/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.5793 - val_loss: 2.5515\n",
      "Epoch 55/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.5866 - val_loss: 2.7648\n",
      "Epoch 56/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.6765 - val_loss: 2.1696\n",
      "Epoch 57/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.6823 - val_loss: 1.8500\n",
      "Epoch 58/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.6291 - val_loss: 2.2445\n",
      "Epoch 59/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.5977 - val_loss: 3.5095\n",
      "Epoch 60/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.6862 - val_loss: 2.5163\n",
      "Epoch 61/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.5580 - val_loss: 3.4242\n",
      "Epoch 62/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.6427 - val_loss: 2.5800\n",
      "Epoch 63/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9982 - loss: 0.0059 - val_accuracy: 0.5678 - val_loss: 3.3855\n",
      "Epoch 64/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.6581 - val_loss: 2.6263\n",
      "Epoch 65/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.5751 - val_loss: 3.6852\n",
      "Epoch 66/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.5446 - val_loss: 4.1473\n",
      "Epoch 67/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.6144 - val_loss: 2.7309\n",
      "Epoch 68/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.5661 - val_loss: 3.2237\n",
      "Epoch 69/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.6653 - val_loss: 2.3102\n",
      "Epoch 70/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.6726 - val_loss: 2.6842\n",
      "Epoch 71/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.6191 - val_loss: 2.7379\n",
      "Epoch 72/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0032 - val_accuracy: 0.6415 - val_loss: 2.4661\n",
      "Epoch 73/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.5558 - val_loss: 3.1632\n",
      "Epoch 74/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.5639 - val_loss: 3.1578\n",
      "Epoch 75/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9986 - loss: 0.0061 - val_accuracy: 0.5133 - val_loss: 4.2521\n",
      "Epoch 76/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.6315 - val_loss: 2.5614\n",
      "Epoch 77/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.6532 - val_loss: 2.4124\n",
      "Epoch 78/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.6621 - val_loss: 2.2757\n",
      "Epoch 79/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.6699 - val_loss: 2.2995\n",
      "Epoch 80/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.6020 - val_loss: 3.4075\n",
      "Epoch 81/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 9.8143e-04 - val_accuracy: 0.6180 - val_loss: 2.8980\n",
      "Epoch 82/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.5939 - val_loss: 3.0641\n",
      "Epoch 83/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0013 - val_accuracy: 0.7089 - val_loss: 2.1719\n",
      "Epoch 84/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.6946 - val_loss: 2.3350\n",
      "Epoch 85/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.6665 - val_loss: 2.5574\n",
      "Epoch 86/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.6342 - val_loss: 3.0116\n",
      "Epoch 87/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.6858 - val_loss: 2.7003\n",
      "Epoch 88/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.6415 - val_loss: 2.9714\n",
      "Epoch 89/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.5716 - val_loss: 3.8403\n",
      "Epoch 90/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.6533 - val_loss: 3.2239\n",
      "Epoch 91/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0060 - val_accuracy: 0.6382 - val_loss: 3.2989\n",
      "Epoch 92/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.5884 - val_loss: 3.8918\n",
      "Epoch 93/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.6536 - val_loss: 3.0168\n",
      "Epoch 94/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.5694 - val_loss: 4.0868\n",
      "Epoch 95/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.6464 - val_loss: 2.6672\n",
      "Epoch 96/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.5999 - val_loss: 3.0488\n",
      "Epoch 97/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.5173 - val_loss: 6.0906\n",
      "Epoch 98/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0054 - val_accuracy: 0.6023 - val_loss: 3.6314\n",
      "Epoch 99/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.6611 - val_loss: 3.0193\n",
      "Epoch 100/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.6155 - val_loss: 3.5233\n",
      "Время обработки: 3.43 с\n",
      "Epoch 1/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.2568 - loss: 2.2352 - val_accuracy: 0.0730 - val_loss: 2.1059\n",
      "Epoch 2/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8156 - loss: 0.5058 - val_accuracy: 0.0730 - val_loss: 3.3493\n",
      "Epoch 3/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9719 - loss: 0.0926 - val_accuracy: 0.2450 - val_loss: 3.7923\n",
      "Epoch 4/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9922 - loss: 0.0350 - val_accuracy: 0.0730 - val_loss: 4.5088\n",
      "Epoch 5/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9954 - loss: 0.0190 - val_accuracy: 0.1192 - val_loss: 4.6976\n",
      "Epoch 6/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0133 - val_accuracy: 0.3506 - val_loss: 4.5920\n",
      "Epoch 7/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9979 - loss: 0.0110 - val_accuracy: 0.2677 - val_loss: 4.8417\n",
      "Epoch 8/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0111 - val_accuracy: 0.1463 - val_loss: 5.0049\n",
      "Epoch 9/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9989 - loss: 0.0091 - val_accuracy: 0.3027 - val_loss: 4.4313\n",
      "Epoch 10/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9989 - loss: 0.0066 - val_accuracy: 0.3579 - val_loss: 4.6772\n",
      "Epoch 11/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0058 - val_accuracy: 0.4086 - val_loss: 4.4908\n",
      "Epoch 12/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0038 - val_accuracy: 0.3576 - val_loss: 4.2235\n",
      "Epoch 13/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.3552 - val_loss: 3.9482\n",
      "Epoch 14/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.0030 - val_accuracy: 0.4152 - val_loss: 3.3136\n",
      "Epoch 15/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.4137 - val_loss: 2.8706\n",
      "Epoch 16/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.4255 - val_loss: 2.5430\n",
      "Epoch 17/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.4756 - val_loss: 1.9081\n",
      "Epoch 18/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9996 - loss: 0.0028 - val_accuracy: 0.5522 - val_loss: 1.5990\n",
      "Epoch 19/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.4798 - val_loss: 2.0146\n",
      "Epoch 20/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.4925 - val_loss: 2.0679\n",
      "Epoch 21/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.5202 - val_loss: 1.9339\n",
      "Epoch 22/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.5169 - val_loss: 1.9145\n",
      "Epoch 23/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.5036 - val_loss: 2.1864\n",
      "Epoch 24/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.5166 - val_loss: 2.4929\n",
      "Epoch 25/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.4641 - val_loss: 2.5305\n",
      "Epoch 26/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.4804 - val_loss: 3.0078\n",
      "Epoch 27/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.5341 - val_loss: 1.9401\n",
      "Epoch 28/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.4964 - val_loss: 2.2641\n",
      "Epoch 29/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.4840 - val_loss: 2.4730\n",
      "Epoch 30/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.4119 - val_loss: 3.6561\n",
      "Epoch 31/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.4879 - val_loss: 2.3418\n",
      "Epoch 32/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.5229 - val_loss: 2.2280\n",
      "Epoch 33/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.5628 - val_loss: 1.9647\n",
      "Epoch 34/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0020 - val_accuracy: 0.5235 - val_loss: 2.3225\n",
      "Epoch 35/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.4807 - val_loss: 2.4941\n",
      "Epoch 36/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.5329 - val_loss: 2.8192\n",
      "Epoch 37/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.6141 - val_loss: 1.6274\n",
      "Epoch 38/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.6035 - val_loss: 1.8439\n",
      "Epoch 39/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.5163 - val_loss: 2.2647\n",
      "Epoch 40/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.4502 - val_loss: 3.0782\n",
      "Epoch 41/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 9.2570e-04 - val_accuracy: 0.5012 - val_loss: 2.2894\n",
      "Epoch 42/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.4949 - val_loss: 2.2483\n",
      "Epoch 43/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.5392 - val_loss: 1.9788\n",
      "Epoch 44/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 7.0161e-04 - val_accuracy: 0.5573 - val_loss: 1.9129\n",
      "Epoch 45/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0020 - val_accuracy: 0.6050 - val_loss: 1.6940\n",
      "Epoch 46/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.5652 - val_loss: 1.9105\n",
      "Epoch 47/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.5658 - val_loss: 1.9756\n",
      "Epoch 48/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 4.0506e-04 - val_accuracy: 0.5769 - val_loss: 1.7989\n",
      "Epoch 49/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.3476e-04 - val_accuracy: 0.5727 - val_loss: 1.9536\n",
      "Epoch 50/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 4.1922e-04 - val_accuracy: 0.5890 - val_loss: 1.7294\n",
      "Epoch 51/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.4852 - val_loss: 3.3728\n",
      "Epoch 52/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.4623 - val_loss: 4.9775\n",
      "Epoch 53/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9989 - loss: 0.0064 - val_accuracy: 0.5951 - val_loss: 1.7616\n",
      "Epoch 54/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.5238 - val_loss: 3.1696\n",
      "Epoch 55/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9966 - loss: 0.0121 - val_accuracy: 0.5709 - val_loss: 1.9289\n",
      "Epoch 56/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.5806 - val_loss: 1.9838\n",
      "Epoch 57/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.5407 - val_loss: 2.4265\n",
      "Epoch 58/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.5027 - val_loss: 2.6645\n",
      "Epoch 59/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.5000 - val_loss: 2.9556\n",
      "Epoch 60/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 9.9873e-04 - val_accuracy: 0.3461 - val_loss: 5.4750\n",
      "Epoch 61/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9991 - loss: 0.0055 - val_accuracy: 0.4544 - val_loss: 3.8319\n",
      "Epoch 62/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.4765 - val_loss: 2.9303\n",
      "Epoch 63/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.5154 - val_loss: 2.4735\n",
      "Epoch 64/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.5302 - val_loss: 2.4099\n",
      "Epoch 65/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.4683 - val_loss: 3.3164\n",
      "Epoch 66/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.5353 - val_loss: 2.9150\n",
      "Epoch 67/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9984 - loss: 0.0025 - val_accuracy: 0.5579 - val_loss: 2.3275\n",
      "Epoch 68/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.5353 - val_loss: 2.2640\n",
      "Epoch 69/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.5493e-04 - val_accuracy: 0.4077 - val_loss: 4.6230\n",
      "Epoch 70/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.4873 - val_loss: 3.3107\n",
      "Epoch 71/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.4946 - val_loss: 3.6925\n",
      "Epoch 72/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 0.4876 - val_loss: 3.8516\n",
      "Epoch 73/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.4707 - val_loss: 3.2914\n",
      "Epoch 74/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 0.4155 - val_loss: 4.7471\n",
      "Epoch 75/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.4285 - val_loss: 3.7319\n",
      "Epoch 76/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.5320 - val_loss: 3.3341\n",
      "Epoch 77/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.4744 - val_loss: 3.7556\n",
      "Epoch 78/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.5486 - val_loss: 3.1461\n",
      "Epoch 79/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.4900 - val_loss: 4.1889\n",
      "Epoch 80/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.5205 - val_loss: 3.6040\n",
      "Epoch 81/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.4587 - val_loss: 4.0957\n",
      "Epoch 82/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9970 - loss: 0.0144 - val_accuracy: 0.4393 - val_loss: 4.4807\n",
      "Epoch 83/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9986 - loss: 0.0029 - val_accuracy: 0.5190 - val_loss: 3.3673\n",
      "Epoch 84/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.5386 - val_loss: 2.9891\n",
      "Epoch 85/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.5419 - val_loss: 3.2793\n",
      "Epoch 86/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.5658 - val_loss: 3.1114\n",
      "Epoch 87/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.5869 - val_loss: 2.8208\n",
      "Epoch 88/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9984 - loss: 0.0040 - val_accuracy: 0.5229 - val_loss: 3.6526\n",
      "Epoch 89/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.4900 - val_loss: 4.0938\n",
      "Epoch 90/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.4943 - val_loss: 4.2408\n",
      "Epoch 91/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.5878 - val_loss: 2.7157\n",
      "Epoch 92/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9973 - loss: 0.0062 - val_accuracy: 0.5229 - val_loss: 3.6961\n",
      "Epoch 93/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.4843 - val_loss: 3.9972\n",
      "Epoch 94/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.5818 - val_loss: 2.7759\n",
      "Epoch 95/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.5435 - val_loss: 3.3535\n",
      "Epoch 96/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.5311 - val_loss: 4.2168\n",
      "Epoch 97/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9974 - loss: 0.0078 - val_accuracy: 0.4765 - val_loss: 4.0631\n",
      "Epoch 98/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.3877 - val_loss: 8.7258\n",
      "Epoch 99/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.4234 - val_loss: 5.2623\n",
      "Epoch 100/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9984 - loss: 0.0098 - val_accuracy: 0.4662 - val_loss: 4.3138\n",
      "Время обработки: 3.71 с\n",
      "Время обработки: 0.89 с\n",
      "Epoch 1/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.2991 - loss: 2.0531 - val_accuracy: 0.1611 - val_loss: 2.5297\n",
      "Epoch 2/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9470 - loss: 0.1601 - val_accuracy: 0.1611 - val_loss: 4.1859\n",
      "Epoch 3/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0281 - val_accuracy: 0.1611 - val_loss: 5.5632\n",
      "Epoch 4/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0118 - val_accuracy: 0.1611 - val_loss: 5.5363\n",
      "Epoch 5/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0088 - val_accuracy: 0.1611 - val_loss: 5.4653\n",
      "Epoch 6/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0067 - val_accuracy: 0.3106 - val_loss: 3.6260\n",
      "Epoch 7/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.3546 - val_loss: 3.1107\n",
      "Epoch 8/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.4293 - val_loss: 2.5908\n",
      "Epoch 9/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.5196 - val_loss: 2.1953\n",
      "Epoch 10/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.5051 - val_loss: 2.0510\n",
      "Epoch 11/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.5631 - val_loss: 1.8736\n",
      "Epoch 12/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.6161 - val_loss: 1.5831\n",
      "Epoch 13/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.6069 - val_loss: 1.6455\n",
      "Epoch 14/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.5661 - val_loss: 2.3716\n",
      "Epoch 15/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.5864 - val_loss: 2.3406\n",
      "Epoch 16/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.5233 - val_loss: 2.2780\n",
      "Epoch 17/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.5609 - val_loss: 2.1609\n",
      "Epoch 18/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.5908 - val_loss: 2.6004\n",
      "Epoch 19/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.6116 - val_loss: 1.9495\n",
      "Epoch 20/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.5392 - val_loss: 2.4502\n",
      "Epoch 21/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.6074 - val_loss: 1.8999\n",
      "Epoch 22/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.6469 - val_loss: 1.7340\n",
      "Epoch 23/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.6038 - val_loss: 2.0796\n",
      "Epoch 24/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.6126 - val_loss: 1.9812\n",
      "Epoch 25/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.4969 - val_loss: 3.4805\n",
      "Epoch 26/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.6357 - val_loss: 1.8041\n",
      "Epoch 27/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 8.3804e-04 - val_accuracy: 0.6585 - val_loss: 1.6975\n",
      "Epoch 28/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.4533 - val_loss: 4.4490\n",
      "Epoch 29/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.6150 - val_loss: 2.2769\n",
      "Epoch 30/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.6204 - val_loss: 2.0069\n",
      "Epoch 31/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.6328 - val_loss: 1.7793\n",
      "Epoch 32/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.6395 - val_loss: 1.7192\n",
      "Epoch 33/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.5764 - val_loss: 2.8282\n",
      "Epoch 34/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.6503 - val_loss: 2.1572\n",
      "Epoch 35/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.5175 - val_loss: 3.1121\n",
      "Epoch 36/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.5948 - val_loss: 2.1861\n",
      "Epoch 37/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.6186 - val_loss: 1.9471\n",
      "Epoch 38/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0020 - val_accuracy: 0.5809 - val_loss: 3.2936\n",
      "Epoch 39/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.5634 - val_loss: 2.9877\n",
      "Epoch 40/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.6186 - val_loss: 2.2375\n",
      "Epoch 41/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.5862 - val_loss: 2.3988\n",
      "Epoch 42/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9977 - loss: 0.0071 - val_accuracy: 0.5193 - val_loss: 3.7214\n",
      "Epoch 43/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.6017 - val_loss: 2.7736\n",
      "Epoch 44/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.6466 - val_loss: 2.1129\n",
      "Epoch 45/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.6427 - val_loss: 1.9300\n",
      "Epoch 46/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.4607 - val_loss: 5.3678\n",
      "Epoch 47/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.6265 - val_loss: 2.1677\n",
      "Epoch 48/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 8.8490e-04 - val_accuracy: 0.5613 - val_loss: 2.8590\n",
      "Epoch 49/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.6349 - val_loss: 2.3261\n",
      "Epoch 50/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.6550 - val_loss: 2.6133\n",
      "Epoch 51/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.6385 - val_loss: 2.1437\n",
      "Epoch 52/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.6099 - val_loss: 2.5190\n",
      "Epoch 53/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.6265 - val_loss: 2.4493\n",
      "Epoch 54/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 0.5862 - val_loss: 2.8314\n",
      "Epoch 55/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.5159 - val_loss: 5.6546\n",
      "Epoch 56/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.5151 - val_loss: 4.1607\n",
      "Epoch 57/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0021 - val_accuracy: 0.5562 - val_loss: 3.0463\n",
      "Epoch 58/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.6095 - val_loss: 2.6016\n",
      "Epoch 59/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.5320 - val_loss: 4.2880\n",
      "Epoch 60/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.5764 - val_loss: 3.3944\n",
      "Epoch 61/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.6108 - val_loss: 2.4671\n",
      "Epoch 62/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.5842 - val_loss: 3.4098\n",
      "Epoch 63/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.5936 - val_loss: 2.9480\n",
      "Epoch 64/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.5529 - val_loss: 3.5581\n",
      "Epoch 65/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.4354 - val_loss: 6.1759\n",
      "Epoch 66/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.5491 - val_loss: 3.7239\n",
      "Epoch 67/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.5141 - val_loss: 5.8590\n",
      "Epoch 68/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0063 - val_accuracy: 0.4865 - val_loss: 6.5135\n",
      "Epoch 69/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.5838 - val_loss: 3.8782\n",
      "Epoch 70/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0012 - val_accuracy: 0.5731 - val_loss: 3.4628\n",
      "Epoch 71/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.6149 - val_loss: 2.5982\n",
      "Epoch 72/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.5909 - val_loss: 3.2148\n",
      "Epoch 73/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.6395 - val_loss: 2.8324\n",
      "Epoch 74/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.6010 - val_loss: 3.1266\n",
      "Epoch 75/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.5574 - val_loss: 3.7267\n",
      "Epoch 76/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.5627 - val_loss: 4.6367\n",
      "Epoch 77/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 9.3146e-04 - val_accuracy: 0.5839 - val_loss: 3.8417\n",
      "Epoch 78/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.5687 - val_loss: 5.0387\n",
      "Epoch 79/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.6357 - val_loss: 3.1891\n",
      "Epoch 80/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 0.4840 - val_loss: 5.7499\n",
      "Epoch 81/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.5483 - val_loss: 4.8434\n",
      "Epoch 82/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.5803 - val_loss: 4.6023\n",
      "Epoch 83/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0064 - val_accuracy: 0.5673 - val_loss: 4.6209\n",
      "Epoch 84/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.5992 - val_loss: 4.0207\n",
      "Epoch 85/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.5921 - val_loss: 4.1174\n",
      "Epoch 86/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.4707 - val_loss: 7.3897\n",
      "Epoch 87/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.5851 - val_loss: 4.0857\n",
      "Epoch 88/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 7.3721e-04 - val_accuracy: 0.5835 - val_loss: 4.0462\n",
      "Epoch 89/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.5746 - val_loss: 4.0179\n",
      "Epoch 90/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.5945 - val_loss: 4.0332\n",
      "Epoch 91/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0010 - val_accuracy: 0.5914 - val_loss: 4.4627\n",
      "Epoch 92/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8671e-04 - val_accuracy: 0.5854 - val_loss: 4.3497\n",
      "Epoch 93/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.5523 - val_loss: 5.1373\n",
      "Epoch 94/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.4955 - val_loss: 7.5270\n",
      "Epoch 95/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.5963 - val_loss: 3.3309\n",
      "Epoch 96/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0053 - val_accuracy: 0.5263 - val_loss: 6.4253\n",
      "Epoch 97/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.5728 - val_loss: 4.0942\n",
      "Epoch 98/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.5263 - val_loss: 5.6791\n",
      "Epoch 99/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.5571 - val_loss: 4.1328\n",
      "Epoch 100/100\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 9.1974e-04 - val_accuracy: 0.6083 - val_loss: 3.4479\n"
     ]
    }
   ],
   "source": [
    "models_vocab_list = []  # Список для моделей с разными размерами словаря\n",
    "models_win_params_list = []  # Список для моделей с разными размерами окна и шагом\n",
    "\n",
    "# Цикл по размерам словаря\n",
    "for vocab_size in VOCAB_SIZES:\n",
    "    with timex():\n",
    "        # Создание токенизатора\n",
    "        tokenizer = Tokenizer(\n",
    "            num_words=vocab_size,\n",
    "            filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff',\n",
    "            lower=True,\n",
    "            split=\" \",\n",
    "            oov_token=\"неизвестное_слово\",\n",
    "            char_level=False,\n",
    "        )\n",
    "        tokenizer.fit_on_texts(text_train)  # Обучение токенизатора на обучающей выборке\n",
    "        # Преобразование текстов в последовательности индексов\n",
    "        seq_train = tokenizer.texts_to_sequences(text_train)\n",
    "        seq_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "    if vocab_size != 20000:\n",
    "        # Для размеров словарей, отличных от 20000\n",
    "        # используем только одно окно = (1000, 100)\n",
    "        win_size, win_hope = WIN_PARAMS[1]\n",
    "        preparation_and_creation_ns(  # Подготовка и создание нейронной сети\n",
    "            models_vocab_list, seq_train, seq_test, vocab_size, win_size, win_hope\n",
    "        )\n",
    "    else:\n",
    "        for win_size, win_hope in WIN_PARAMS:\n",
    "            # Для размера словаря 20000 используем все окна\n",
    "            preparation_and_creation_ns(\n",
    "                models_win_params_list,\n",
    "                seq_train,\n",
    "                seq_test,\n",
    "                vocab_size,\n",
    "                win_size,\n",
    "                win_hope,\n",
    "            )\n",
    "        # Добавляем параметры модели с размером словаря 20000 и окном (1000, 100)\n",
    "        # в первый список для сравнения с другими размерами словаря\n",
    "        models_vocab_list.append(models_win_params_list[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод сравнительных таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание сравнительных таблиц\n",
    "df1 = pd.DataFrame(models_vocab_list)\n",
    "df2 = pd.DataFrame(models_win_params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VOCAB_SIZE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WIN_SIZE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WIN_HOPE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Точность",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Точность на проверочной выборке",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6a84b8bf-64fc-489d-a898-a7189f89fa75",
       "rows": [
        [
         "0",
         "5000",
         "1000",
         "100",
         "0.999716579914093",
         "0.6054441928863525"
        ],
        [
         "1",
         "10000",
         "1000",
         "100",
         "0.9992630481719971",
         "0.5776249170303345"
        ],
        [
         "2",
         "20000",
         "1000",
         "100",
         "0.9987528324127197",
         "0.6154651641845703"
        ],
        [
         "3",
         "40000",
         "1000",
         "100",
         "0.9994897842407227",
         "0.6082859635353088"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOCAB_SIZE</th>\n",
       "      <th>WIN_SIZE</th>\n",
       "      <th>WIN_HOPE</th>\n",
       "      <th>Точность</th>\n",
       "      <th>Точность на проверочной выборке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.605444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.577625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998753</td>\n",
       "      <td>0.615465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.608286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VOCAB_SIZE  WIN_SIZE  WIN_HOPE  Точность  Точность на проверочной выборке\n",
       "0        5000      1000       100  0.999717                         0.605444\n",
       "1       10000      1000       100  0.999263                         0.577625\n",
       "2       20000      1000       100  0.998753                         0.615465\n",
       "3       40000      1000       100  0.999490                         0.608286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VOCAB_SIZE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WIN_SIZE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WIN_HOPE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Точность",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Точность на проверочной выборке",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3225827d-82d5-447c-9ad0-f69261164dd8",
       "rows": [
        [
         "0",
         "20000",
         "500",
         "50",
         "0.9995471835136414",
         "0.5626721978187561"
        ],
        [
         "1",
         "20000",
         "1000",
         "100",
         "0.9987528324127197",
         "0.6154651641845703"
        ],
        [
         "2",
         "20000",
         "2000",
         "200",
         "0.9980664253234863",
         "0.4662039875984192"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOCAB_SIZE</th>\n",
       "      <th>WIN_SIZE</th>\n",
       "      <th>WIN_HOPE</th>\n",
       "      <th>Точность</th>\n",
       "      <th>Точность на проверочной выборке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.999547</td>\n",
       "      <td>0.562672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998753</td>\n",
       "      <td>0.615465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>2000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998066</td>\n",
       "      <td>0.466204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VOCAB_SIZE  WIN_SIZE  WIN_HOPE  Точность  Точность на проверочной выборке\n",
       "0       20000       500        50  0.999547                         0.562672\n",
       "1       20000      1000       100  0.998753                         0.615465\n",
       "2       20000      2000       200  0.998066                         0.466204"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "global-cKEoLTwX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
